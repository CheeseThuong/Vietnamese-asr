# ğŸš€ HÆ°á»›ng dáº«n Training trÃªn Google Colab

## ğŸ“‹ Giá»›i thiá»‡u

Google Colab cung cáº¥p **GPU miá»…n phÃ­** (Tesla T4, 15GB RAM) lÃ½ tÆ°á»Ÿng cho training ASR model.

**So sÃ¡nh:**
- **Local CPU**: ~6 ngÃ y âŒ
- **Colab GPU**: ~15-20 giá» âœ…
- **Chi phÃ­**: Miá»…n phÃ­ (Colab free) hoáº·c $10/thÃ¡ng (Colab Pro)

---

## ğŸ¯ Quick Start

### BÆ°á»›c 1: Chuáº©n bá»‹ Dataset (TrÃªn mÃ¡y local)

```bash
# Cháº¡y script chuáº©n bá»‹ dataset
python prepare_vivos.py
```

Sáº½ táº¡o folder `processed_data_vivos/` vá»›i:
- `train.jsonl` (~10,494 samples)
- `validation.jsonl` (~1,166 samples)
- `test.jsonl` (~760 samples)

### BÆ°á»›c 2: Upload Dataset lÃªn Google Drive

1. Má»Ÿ Google Drive
2. Táº¡o folder: `MyDrive/VietnameseASR/data/`
3. Upload 3 files `.jsonl` vÃ o folder nÃ y
4. *(Optional)* Upload folder `src/` vÃ o `MyDrive/VietnameseASR/code/`

**Cáº¥u trÃºc khuyáº¿n nghá»‹:**
```
MyDrive/
â””â”€â”€ VietnameseASR/
    â”œâ”€â”€ data/              # Dataset
    â”‚   â”œâ”€â”€ train.jsonl
    â”‚   â”œâ”€â”€ validation.jsonl
    â”‚   â””â”€â”€ test.jsonl
    â”œâ”€â”€ code/              # Source code (optional náº¿u dÃ¹ng GitHub)
    â”‚   â””â”€â”€ src/
    â”œâ”€â”€ models/            # Auto-created khi training
    â””â”€â”€ final_model/       # Auto-created sau training
```

### BÆ°á»›c 3: Má»Ÿ Notebook trÃªn Colab

**Option 1: Upload file .ipynb**
1. Má»Ÿ https://colab.research.google.com
2. File â†’ Upload notebook
3. Chá»n `colab_train.ipynb`

**Option 2: Tá»« Google Drive**
1. Upload `colab_train.ipynb` vÃ o Drive
2. Double-click file â†’ Open with â†’ Google Colaboratory

**Option 3: Tá»« GitHub**
1. Push code lÃªn GitHub repo
2. Colab â†’ File â†’ Open notebook â†’ GitHub
3. Nháº­p repo URL

### BÆ°á»›c 4: Báº­t GPU

**QUAN TRá»ŒNG!** Pháº£i báº­t GPU trÆ°á»›c khi cháº¡y:

1. Runtime â†’ Change runtime type
2. Hardware accelerator â†’ **GPU**
3. GPU type â†’ **T4** (free) hoáº·c **A100** (Pro)
4. Save

Verify GPU:
```python
import torch
print(torch.cuda.is_available())  # Pháº£i lÃ  True
print(torch.cuda.get_device_name(0))  # Tesla T4
```

### BÆ°á»›c 5: Cháº¡y tá»«ng cell

**Cháº¡y tuáº§n tá»± tá»« trÃªn xuá»‘ng:**

1. **Cell 1**: Check GPU âœ…
2. **Cell 2**: Mount Google Drive âœ…
3. **Cell 3-4**: Install dependencies âœ…
4. **Cell 5**: Upload/Clone source code âœ…
5. **Cell 6**: Check dataset âœ…
6. **Cell 7**: Config âœ…
7. **Cell 8**: Load processor & datasets âœ…
8. **Cell 9**: Create model âœ…
9. **Cell 10**: **START TRAINING** ğŸš€
10. **Cell 11**: Save final model âœ…

---

## âš™ï¸ Configuration

### Config máº·c Ä‘á»‹nh (GPU T4):

```python
config = {
    'pretrained_model': 'nguyenvulebinh/wav2vec2-base-vietnamese-250h',
    'num_train_epochs': 30,
    'batch_size': 16,              # T4 (15GB) ~ batch 16
    'gradient_accumulation_steps': 1,
    'learning_rate': 3e-4,
    'use_fp16': True,              # Mixed precision
    'save_steps': 500,
    'eval_steps': 500,
}
```

### Äiá»u chá»‰nh cho GPU khÃ¡c nhau:

| GPU | VRAM | Batch Size | Time (30 epochs) |
|-----|------|------------|------------------|
| T4 (free) | 15GB | 12-16 | ~18-20h |
| V100 (Pro) | 16GB | 16-20 | ~12-15h |
| A100 (Pro) | 40GB | 24-32 | ~8-10h |

**Náº¿u Out of Memory:**
```python
config['batch_size'] = 8
config['gradient_accumulation_steps'] = 2
```

---

## ğŸ“Š Monitoring Training

### TensorBoard (Real-time)

```python
%load_ext tensorboard
%tensorboard --logdir /content/drive/MyDrive/VietnameseASR/models/wav2vec2-vietnamese/runs
```

### GPU Usage

```python
!nvidia-smi
```

### Training Progress

```python
# View logs
!tail -100 /content/drive/MyDrive/VietnameseASR/models/wav2vec2-vietnamese/trainer_state.json

# List checkpoints
!ls -lh /content/drive/MyDrive/VietnameseASR/models/wav2vec2-vietnamese/checkpoint-*/
```

### Training History

```python
import pandas as pd
history = pd.read_csv("/content/drive/MyDrive/VietnameseASR/training_history.csv")

# Plot WER over time
import matplotlib.pyplot as plt
plt.plot(history['eval_wer'])
plt.title('Word Error Rate')
plt.xlabel('Step')
plt.ylabel('WER')
plt.show()
```

---

## ğŸ”„ Xá»­ lÃ½ Timeout

### Váº¥n Ä‘á»:
- **Colab Free**: Timeout sau ~12 giá»
- **Training cáº§n**: ~15-20 giá»
- â†’ Bá»‹ ngáº¯t giá»¯a chá»«ng!

### Giáº£i phÃ¡p 1: Chia nhá» training

**Session 1 (10 epochs):**
```python
config['num_train_epochs'] = 10
# Run training...
# Sau 10 epochs, checkpoint auto-saved
```

**Session 2 (epochs 11-20):**
```python
# Má»Ÿ notebook má»›i hoáº·c restart
config['num_train_epochs'] = 20
config['resume_from_checkpoint'] = '/content/drive/MyDrive/VietnameseASR/models/wav2vec2-vietnamese/checkpoint-6000'
# Continue training...
```

**Session 3 (epochs 21-30):**
```python
config['num_train_epochs'] = 30
config['resume_from_checkpoint'] = '/content/drive/.../checkpoint-12000'
```

### Giáº£i phÃ¡p 2: Keep-alive script

```python
# Cell riÃªng - Cháº¡y song song vá»›i training
import time
from google.colab import output

while True:
    time.sleep(60)  # Má»—i 1 phÃºt
    output.clear()
    print("Keep-alive ping")
```

### Giáº£i phÃ¡p 3: Colab Pro

- $10/thÃ¡ng
- Timeout: ~24 giá» (Ä‘á»§ cho 1 láº§n cháº¡y)
- Better GPU: V100/A100
- Priority access

---

## ğŸ’¾ Checkpointing Strategy

### Auto-save má»—i 500 steps:

```python
training_args = TrainingArguments(
    save_steps=500,              # LÆ°u má»—i 500 steps
    save_total_limit=2,          # Chá»‰ giá»¯ 2 checkpoint gáº§n nháº¥t
    load_best_model_at_end=True, # Load model tá»‘t nháº¥t
)
```

### Manual checkpoint:

```python
# LÆ°u táº¡i báº¥t ká»³ lÃºc nÃ o
trainer.save_model("/content/drive/MyDrive/VietnameseASR/checkpoint_manual")
```

### Resume tá»« checkpoint:

```python
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    # ... other args ...
    resume_from_checkpoint="/content/drive/.../checkpoint-5000"
)
```

---

## ğŸ“¥ Download Model

### Option 1: Download tá»« Drive

1. Training xong â†’ Model saved to Drive
2. VÃ o Drive â†’ Download folder `final_model/`
3. Giáº£i nÃ©n trÃªn mÃ¡y local

### Option 2: Download trá»±c tiáº¿p tá»« Colab

```python
# Zip model
!zip -r final_model.zip /content/drive/MyDrive/VietnameseASR/final_model/

# Download
from google.colab import files
files.download('final_model.zip')
```

### Option 3: Upload lÃªn HuggingFace Hub

```python
from huggingface_hub import HfApi, create_repo

# Login (cáº§n HF token)
!huggingface-cli login

# Create repo
repo_name = "your-username/wav2vec2-vietnamese-asr"
create_repo(repo_name, private=False)

# Upload
model.push_to_hub(repo_name)
processor.push_to_hub(repo_name)

print(f"âœ… Uploaded to: https://huggingface.co/{repo_name}")
```

---

## ğŸ§ª Test Model

### Test trÃªn notebook:

```python
# Load model
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
import soundfile as sf
import torch

model = Wav2Vec2ForCTC.from_pretrained("/content/drive/.../final_model")
processor = Wav2Vec2Processor.from_pretrained("/content/drive/.../final_model")
model.eval()

# Transcribe
def transcribe(audio_path):
    speech, sr = sf.read(audio_path)
    inputs = processor(speech, sampling_rate=16000, return_tensors="pt")
    
    with torch.no_grad():
        logits = model(**inputs).logits
    
    pred_ids = torch.argmax(logits, dim=-1)
    return processor.batch_decode(pred_ids)[0]

# Test
result = transcribe("/path/to/audio.wav")
print(f"Káº¿t quáº£: {result}")
```

### Upload audio Ä‘á»ƒ test:

```python
from google.colab import files

# Upload file
uploaded = files.upload()

# Get filename
audio_file = list(uploaded.keys())[0]

# Transcribe
result = transcribe(audio_file)
print(f"Transcription: {result}")
```

---

## âš ï¸ Common Issues

### Issue 1: Runtime disconnected

**NguyÃªn nhÃ¢n:** Colab timeout hoáº·c máº¥t káº¿t ná»‘i

**Giáº£i phÃ¡p:**
- Checkpoints Ä‘Ã£ lÆ°u vÃ o Drive â†’ An toÃ n!
- Resume tá»« checkpoint gáº§n nháº¥t:
```python
config['resume_from_checkpoint'] = '/content/drive/.../checkpoint-XXXX'
```

### Issue 2: Out of Memory (OOM)

**NguyÃªn nhÃ¢n:** Batch size quÃ¡ lá»›n

**Giáº£i phÃ¡p:**
```python
# Giáº£m batch size
config['batch_size'] = 8

# TÄƒng gradient accumulation (giá»¯ effective batch size)
config['gradient_accumulation_steps'] = 2

# Gradient checkpointing (tiáº¿t kiá»‡m memory)
config['gradient_checkpointing'] = True
```

### Issue 3: Dataset not found

**NguyÃªn nhÃ¢n:** ChÆ°a mount Drive hoáº·c Ä‘Æ°á»ng dáº«n sai

**Giáº£i phÃ¡p:**
```python
# Re-mount Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Check path
!ls /content/drive/MyDrive/VietnameseASR/data/
```

### Issue 4: Training quÃ¡ cháº­m

**NguyÃªn nhÃ¢n:** KhÃ´ng dÃ¹ng GPU hoáº·c cháº¡y trÃªn CPU

**Giáº£i phÃ¡p:**
```python
# Check GPU
assert torch.cuda.is_available(), "GPU not enabled!"

# Verify runtime
# Runtime â†’ Change runtime type â†’ GPU
```

---

## ğŸ“ˆ Expected Results

### Training Metrics:

| Metric | Initial | After 10 epochs | After 30 epochs |
|--------|---------|-----------------|-----------------|
| **WER** | ~50% | ~25-30% | ~15-20% |
| **CER** | ~30% | ~15-18% | ~8-12% |
| **Loss** | ~10 | ~2-3 | ~0.5-1.0 |

### Training Time:

- **GPU T4**: ~18-20 giá» (30 epochs)
- **GPU V100**: ~12-15 giá»
- **GPU A100**: ~8-10 giá»

### Model Size:

- **Original**: ~400MB
- **After quantization**: ~100MB (75% reduction)

---

## ğŸ¯ Tips & Best Practices

### 1. Start Small, Scale Up

```python
# Test vá»›i subset nhá» trÆ°á»›c (5-10 phÃºt)
train_dataset = train_dataset.select(range(100))
config['num_train_epochs'] = 2

# Sau khi confirm code cháº¡y OK â†’ Train full
```

### 2. Monitor Regularly

- Check TensorBoard má»—i 1-2 giá»
- Theo dÃµi WER/Loss trends
- Stop sá»›m náº¿u overfit

### 3. Use Early Stopping

```python
from transformers import EarlyStoppingCallback

early_stopping = EarlyStoppingCallback(
    early_stopping_patience=3,  # Stop sau 3 evals khÃ´ng improve
    early_stopping_threshold=0.01
)

trainer = Trainer(..., callbacks=[early_stopping])
```

### 4. Save Intermediate Results

```python
# LÆ°u má»—i 1000 steps thay vÃ¬ 500 náº¿u muá»‘n tiáº¿t kiá»‡m disk
training_args.save_steps = 1000
```

### 5. Backup to Multiple Locations

```python
# Sau training xong, copy sang nÆ¡i khÃ¡c
!cp -r /content/drive/MyDrive/VietnameseASR/final_model /content/drive/MyDrive/Backups/
```

---

## ğŸ“š Resources

- **Colab Docs**: https://colab.research.google.com/notebooks/intro.ipynb
- **HuggingFace Wav2Vec2**: https://huggingface.co/docs/transformers/model_doc/wav2vec2
- **Transformers Trainer**: https://huggingface.co/docs/transformers/main_classes/trainer

---

## ğŸ†˜ Need Help?

**Gáº·p váº¥n Ä‘á»?** Check:
1. Runtime â†’ Change runtime type â†’ GPU âœ…
2. Drive mounted âœ…
3. Dataset files tá»“n táº¡i âœ…
4. GPU memory khÃ´ng quÃ¡ táº£i âœ…

**Still stuck?** Share error log Ä‘á»ƒ debug!

---

**ChÃºc báº¡n training thÃ nh cÃ´ng! ğŸš€**

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5219cd60",
   "metadata": {},
   "source": [
    "# üé§ Vietnamese ASR Training - Google Colab\n",
    "\n",
    "**Nh·∫≠n d·∫°ng gi·ªçng n√≥i ti·∫øng Vi·ªát v·ªõi Wav2Vec2**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Setup Checklist\n",
    "- [ ] Runtime ‚Üí Change runtime type ‚Üí **GPU (T4)**\n",
    "- [ ] Mount Google Drive\n",
    "- [ ] Upload dataset l√™n Drive\n",
    "- [ ] Run all cells\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e4e957",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîß Environment Info\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(\"\\n‚úÖ GPU Ready!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: GPU not available!\")\n",
    "    print(\"Go to: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14361ab",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# T·∫°o working directory\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive/VietnameseASR\"\n",
    "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
    "\n",
    "print(f\"\\n‚úì Drive mounted at: {DRIVE_ROOT}\")\n",
    "print(\"\\nüìÇ C·∫•u tr√∫c th∆∞ m·ª•c khuy·∫øn ngh·ªã:\")\n",
    "print(f\"{DRIVE_ROOT}/\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ data/               # Dataset files\")\n",
    "print(\"  ‚îÇ   ‚îú‚îÄ‚îÄ train.jsonl\")\n",
    "print(\"  ‚îÇ   ‚îú‚îÄ‚îÄ validation.jsonl\")\n",
    "print(\"  ‚îÇ   ‚îî‚îÄ‚îÄ test.jsonl\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ models/             # Checkpoints (auto-created)\")\n",
    "print(\"  ‚îî‚îÄ‚îÄ final_model/        # Final output (auto-created)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9ad2f",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9342c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install packages (silent mode)\n",
    "!pip install -q transformers datasets evaluate jiwer soundfile librosa accelerate tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4126a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")\n",
    "print(f\"   - transformers: {transformers.__version__}\")\n",
    "print(f\"   - datasets: {datasets.__version__}\")\n",
    "print(f\"   - evaluate: {evaluate.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d36b5",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Upload Source Code\n",
    "\n",
    "**Option 1: Clone t·ª´ GitHub (Khuy·∫øn ngh·ªã)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/YOUR_USERNAME/vietnamese-asr.git\n",
    "%cd vietnamese-asr\n",
    "\n",
    "# Ho·∫∑c n·∫øu ƒë√£ clone r·ªìi, ch·ªâ c·∫ßn pull\n",
    "# !git pull origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28c384",
   "metadata": {},
   "source": [
    "**Option 2: Upload t·ª´ Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6210ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N·∫øu ƒë√£ upload source code l√™n Drive\n",
    "import sys\n",
    "CODE_DIR = f\"{DRIVE_ROOT}/code\"  # Folder ch·ª©a src/\n",
    "sys.path.insert(0, CODE_DIR)\n",
    "\n",
    "print(f\"‚úì Source code loaded from: {CODE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add7a77",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Check Dataset\n",
    "\n",
    "**H∆∞·ªõng d·∫´n upload dataset:**\n",
    "1. Ch·∫°y `python prepare_vivos.py` tr√™n m√°y local\n",
    "2. Upload folder `processed_data_vivos/` l√™n Google Drive\n",
    "3. ƒê·∫∑t v√†o: `MyDrive/VietnameseASR/data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c90894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n dataset\n",
    "DATA_DIR = Path(f\"{DRIVE_ROOT}/data\")\n",
    "\n",
    "# Ki·ªÉm tra files\n",
    "required_files = ['train.jsonl', 'validation.jsonl', 'test.jsonl']\n",
    "missing = [f for f in required_files if not (DATA_DIR / f).exists()]\n",
    "\n",
    "if missing:\n",
    "    print(\"‚ùå Missing dataset files:\")\n",
    "    for f in missing:\n",
    "        print(f\"   - {f}\")\n",
    "    print(f\"\\nüìÅ Expected location: {DATA_DIR}\")\n",
    "    print(\"\\nüí° Upload dataset files to Google Drive first!\")\n",
    "else:\n",
    "    print(\"‚úÖ All dataset files found!\")\n",
    "    # Count samples\n",
    "    for file in required_files:\n",
    "        with open(DATA_DIR / file, 'r', encoding='utf-8') as f:\n",
    "            count = sum(1 for _ in f)\n",
    "        print(f\"   - {file}: {count:,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3472dbb8",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287096f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Configuration - T·ªëi ∆∞u cho Colab GPU\n",
    "config = {\n",
    "    'pretrained_model': 'nguyenvulebinh/wav2vec2-base-vietnamese-250h',\n",
    "    'num_train_epochs': 30,          # S·ªë epochs\n",
    "    'batch_size': 16,                # GPU T4 ~ 16GB RAM\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'learning_rate': 3e-4,\n",
    "    'use_fp16': True,                # Mixed precision training\n",
    "    'apply_quantization': False,     # Kh√¥ng quantize khi training\n",
    "    'save_steps': 500,               # L∆∞u checkpoint m·ªói 500 steps\n",
    "    'eval_steps': 500,               # Evaluate m·ªói 500 steps\n",
    "}\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR = Path(f\"{DRIVE_ROOT}/models/wav2vec2-vietnamese\")\n",
    "FINAL_MODEL_DIR = Path(f\"{DRIVE_ROOT}/final_model\")\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FINAL_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save config\n",
    "with open(OUTPUT_DIR / 'config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   - {key}: {value}\")\n",
    "print(f\"\\nüìÅ Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996da0e5",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Load Processor & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "from src.data.preprocessing import load_and_prepare_datasets\n",
    "\n",
    "print(\"Loading processor...\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(config['pretrained_model'])\n",
    "\n",
    "print(\"\\nLoading datasets...\")\n",
    "train_dataset, val_dataset, test_dataset = load_and_prepare_datasets(\n",
    "    str(DATA_DIR / 'train.jsonl'),\n",
    "    str(DATA_DIR / 'validation.jsonl'),\n",
    "    str(DATA_DIR / 'test.jsonl'),\n",
    "    processor\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets loaded:\")\n",
    "print(f\"   - Train: {len(train_dataset):,} samples\")\n",
    "print(f\"   - Validation: {len(val_dataset):,} samples\")\n",
    "print(f\"   - Test: {len(test_dataset):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5678ff9",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.train_wav2vec2 import create_model\n",
    "\n",
    "print(\"Creating model...\")\n",
    "vocab_size = len(processor.tokenizer)\n",
    "model = create_model(vocab_size, config['pretrained_model'])\n",
    "\n",
    "# Move to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úÖ Model ready on {device}\")\n",
    "print(f\"   - Total parameters: {total_params:,}\")\n",
    "print(f\"   - Trainable: {trainable_params:,}\")\n",
    "print(f\"   - Frozen: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10264c",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Start Training\n",
    "\n",
    "**‚è±Ô∏è Estimated time: 15-20 hours on T4 GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1711c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.train_wav2vec2 import train_model\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ Starting Training...\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANT:\")\n",
    "print(\"   - Keep this tab open!\")\n",
    "print(\"   - Colab timeout: ~12 hours\")\n",
    "print(\"   - Checkpoints auto-saved to Drive every 500 steps\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Train\n",
    "trainer = train_model(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    processor=processor,\n",
    "    output_dir=str(OUTPUT_DIR),\n",
    "    num_train_epochs=config['num_train_epochs'],\n",
    "    batch_size=config['batch_size'],\n",
    "    gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "    learning_rate=config['learning_rate'],\n",
    "    use_fp16=config['use_fp16']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b71d0bb",
   "metadata": {},
   "source": [
    "## üîü Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c156254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving final model...\")\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(str(FINAL_MODEL_DIR))\n",
    "processor.save_pretrained(str(FINAL_MODEL_DIR))\n",
    "\n",
    "# Save training history\n",
    "import pandas as pd\n",
    "if hasattr(trainer.state, 'log_history'):\n",
    "    history_df = pd.DataFrame(trainer.state.log_history)\n",
    "    history_df.to_csv(f\"{DRIVE_ROOT}/training_history.csv\", index=False)\n",
    "    print(f\"‚úì Training history saved\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"üì¶ Final model: {FINAL_MODEL_DIR}\")\n",
    "print(f\"\\nüí° Model ƒë√£ l∆∞u v√†o Google Drive, b·∫°n c√≥ th·ªÉ:\")\n",
    "print(f\"   1. Download v·ªÅ m√°y t·ª´ Drive\")\n",
    "print(f\"   2. D√πng tr·ª±c ti·∫øp t·ª´ Drive trong notebook kh√°c\")\n",
    "print(f\"   3. Upload l√™n HuggingFace Hub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cdf5d4",
   "metadata": {},
   "source": [
    "## üìä Monitor Training (Optional)\n",
    "\n",
    "Ch·∫°y cell n√†y trong l√∫c training ƒë·ªÉ theo d√µi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {OUTPUT_DIR}/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU monitoring\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check latest checkpoint\n",
    "!ls -lh {OUTPUT_DIR}/checkpoint-*/ | tail -5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c183b1",
   "metadata": {},
   "source": [
    "## üéØ Test Model (After Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import soundfile as sf\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(str(FINAL_MODEL_DIR))\n",
    "processor = Wav2Vec2Processor.from_pretrained(str(FINAL_MODEL_DIR))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio file\n",
    "def transcribe(audio_path):\n",
    "    # Load audio\n",
    "    speech, sr = sf.read(audio_path)\n",
    "    \n",
    "    # Process\n",
    "    inputs = processor(speech, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    # Decode\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(pred_ids)[0]\n",
    "    \n",
    "    return transcription\n",
    "\n",
    "# Test\n",
    "# audio_file = \"/path/to/audio.wav\"\n",
    "# result = transcribe(audio_file)\n",
    "# print(f\"Transcription: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa6409",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Tips\n",
    "\n",
    "### Tr√°nh Colab timeout:\n",
    "- Training m·∫•t ~15-20h, Colab free timeout sau ~12h\n",
    "- **Gi·∫£i ph√°p:** Chia nh·ªè training th√†nh nhi·ªÅu session\n",
    "  ```python\n",
    "  # Session 1: Train 10 epochs\n",
    "  config['num_train_epochs'] = 10\n",
    "  \n",
    "  # Session 2: Resume t·ª´ checkpoint, train th√™m 10 epochs\n",
    "  config['resume_from_checkpoint'] = str(OUTPUT_DIR / 'checkpoint-5000')\n",
    "  config['num_train_epochs'] = 20\n",
    "  ```\n",
    "\n",
    "### Colab Pro:\n",
    "- Timeout: ~24h\n",
    "- Better GPU: A100/V100\n",
    "- Training time: ~8-10h\n",
    "\n",
    "### Auto-save to Drive:\n",
    "Checkpoints t·ª± ƒë·ªông l∆∞u v√†o Drive m·ªói 500 steps, an to√†n n·∫øu Colab disconnect!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

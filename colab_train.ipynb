{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5219cd60",
   "metadata": {},
   "source": [
    "# üé§ Vietnamese ASR Training - Google Colab\n",
    "\n",
    "**Nh·∫≠n d·∫°ng gi·ªçng n√≥i ti·∫øng Vi·ªát v·ªõi Wav2Vec2**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Setup Checklist\n",
    "- [ ] Runtime ‚Üí Change runtime type ‚Üí **GPU (T4)**\n",
    "- [ ] Mount Google Drive\n",
    "- [ ] Upload dataset l√™n Drive\n",
    "- [ ] Run all cells\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e4e957",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîß Environment Info\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(\"\\n‚úÖ GPU Ready!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: GPU not available!\")\n",
    "    print(\"Go to: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14361ab",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# T·∫°o working directory\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive/VietnameseASR\"\n",
    "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
    "\n",
    "print(f\"\\n‚úì Drive mounted at: {DRIVE_ROOT}\")\n",
    "print(\"\\nüìÇ C·∫•u tr√∫c th∆∞ m·ª•c khuy·∫øn ngh·ªã:\")\n",
    "print(f\"{DRIVE_ROOT}/\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ data/               # Dataset files\")\n",
    "print(\"  ‚îÇ   ‚îú‚îÄ‚îÄ train.jsonl\")\n",
    "print(\"  ‚îÇ   ‚îú‚îÄ‚îÄ validation.jsonl\")\n",
    "print(\"  ‚îÇ   ‚îî‚îÄ‚îÄ test.jsonl\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ models/             # Checkpoints (auto-created)\")\n",
    "print(\"  ‚îî‚îÄ‚îÄ final_model/        # Final output (auto-created)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9ad2f",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9342c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install packages (silent mode)\n",
    "!pip install -q transformers datasets evaluate jiwer soundfile librosa accelerate tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4126a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")\n",
    "print(f\"   - transformers: {transformers.__version__}\")\n",
    "print(f\"   - datasets: {datasets.__version__}\")\n",
    "print(f\"   - evaluate: {evaluate.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d36b5",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Clone Source Code t·ª´ GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if repo already exists\n",
    "if os.path.exists('/content/Vietnamese-asr'):\n",
    "    print(\"‚ö†Ô∏è Repository already exists, updating...\")\n",
    "    os.chdir('/content/Vietnamese-asr')\n",
    "    !git pull origin main\n",
    "else:\n",
    "    print(\"üì• Cloning repository...\")\n",
    "    !git clone https://github.com/CheeseThuong/Vietnamese-asr.git\n",
    "    os.chdir('/content/Vietnamese-asr')\n",
    "\n",
    "# CRITICAL: Add to Python path\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "    \n",
    "print(f\"\\n‚úÖ Repository ready\")\n",
    "print(f\"üìÇ Location: {os.getcwd()}\")\n",
    "print(f\"üêç Python path: {sys.path[0]}\")\n",
    "\n",
    "# Verify structure\n",
    "print(f\"\\nüìÅ Repository structure:\")\n",
    "!ls -la\n",
    "print(f\"\\nüìÅ src/ contents:\")\n",
    "!ls -la src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8450bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Python imports (DEBUG)\n",
    "print(\"=\"*60)\n",
    "print(\"üîç Verifying imports...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    from src.data.preprocessing import load_and_prepare_datasets\n",
    "    from src.training.train_wav2vec2 import create_model, train_model\n",
    "    print(\"‚úÖ All imports successful!\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"‚ùå Import failed: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(f\"  Current dir: {os.getcwd()}\")\n",
    "    print(f\"  Python path: {sys.path[0]}\")\n",
    "    print(f\"  src/ exists: {os.path.exists('src')}\")\n",
    "    \n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add7a77",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Check Dataset\n",
    "\n",
    "**H∆∞·ªõng d·∫´n upload dataset:**\n",
    "1. **Tr√™n m√°y local**, ch·∫°y: `python convert_to_relative_paths.py`\n",
    "2. Upload 3 files t·ª´ `processed_data_vivos/` l√™n Google Drive\n",
    "3. ƒê·∫∑t v√†o: `MyDrive/VietnameseASR/data/`\n",
    "\n",
    "**‚ö†Ô∏è QUAN TR·ªåNG**: Files ph·∫£i c√≥ **relative paths** (v√≠ d·ª•: `Data/vivos/vivos/train/...`) ch·ª© KH√îNG ph·∫£i absolute paths (`D:\\Projects\\...`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c90894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n dataset\n",
    "DATA_DIR = Path(f\"{DRIVE_ROOT}/data\")\n",
    "\n",
    "# Ki·ªÉm tra files\n",
    "required_files = ['train.jsonl', 'validation.jsonl', 'test.jsonl']\n",
    "missing = [f for f in required_files if not (DATA_DIR / f).exists()]\n",
    "\n",
    "if missing:\n",
    "    print(\"‚ùå Missing dataset files:\")\n",
    "    for f in missing:\n",
    "        print(f\"   - {f}\")\n",
    "    print(f\"\\nüìÅ Expected location: {DATA_DIR}\")\n",
    "    print(\"\\nüí° Upload dataset files to Google Drive first!\")\n",
    "else:\n",
    "    print(\"‚úÖ All dataset files found!\")\n",
    "    # Count samples and check paths\n",
    "    for file in required_files:\n",
    "        filepath = DATA_DIR / file\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            count = len(lines)\n",
    "            \n",
    "        # Check sample path\n",
    "        if lines:\n",
    "            sample = json.loads(lines[0])\n",
    "            audio_path = sample['audio_path']\n",
    "            is_relative = not os.path.isabs(audio_path)\n",
    "            path_type = \"‚úÖ relative\" if is_relative else \"‚ö†Ô∏è absolute\"\n",
    "            \n",
    "            print(f\"   - {file}: {count:,} samples ({path_type})\")\n",
    "            print(f\"     Sample path: {audio_path[:80]}...\")\n",
    "            \n",
    "            # Warning if absolute paths found\n",
    "            if not is_relative:\n",
    "                print(f\"     ‚ö†Ô∏è WARNING: Absolute paths detected! Will fail on Colab.\")\n",
    "                print(f\"     üí° Run 'python convert_to_relative_paths.py' locally first!\")\n",
    "        else:\n",
    "            print(f\"   - {file}: {count:,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9402765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset files t·ª´ Drive v√†o working directory c·ªßa Colab\n",
    "import shutil\n",
    "\n",
    "print(\"üìã Setting up dataset in Colab workspace...\")\n",
    "\n",
    "# T·∫°o folder Data trong Colab\n",
    "COLAB_DATA_DIR = Path(\"/content/Vietnamese-asr/Data\")\n",
    "COLAB_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy folder vivos t·ª´ Drive (n·∫øu c√≥)\n",
    "DRIVE_VIVOS = Path(f\"{DRIVE_ROOT}/vivos\")\n",
    "COLAB_VIVOS = COLAB_DATA_DIR / \"vivos\"\n",
    "\n",
    "if DRIVE_VIVOS.exists():\n",
    "    print(f\"üìÇ Copying VIVOS dataset from Drive...\")\n",
    "    print(f\"   Source: {DRIVE_VIVOS}\")\n",
    "    print(f\"   Destination: {COLAB_VIVOS}\")\n",
    "    \n",
    "    if COLAB_VIVOS.exists():\n",
    "        shutil.rmtree(COLAB_VIVOS)\n",
    "    shutil.copytree(DRIVE_VIVOS, COLAB_VIVOS)\n",
    "    print(f\"   ‚úÖ Copied successfully!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è VIVOS audio folder not found at: {DRIVE_VIVOS}\")\n",
    "    print(f\"üí° Make sure to upload the 'vivos' folder to Drive\")\n",
    "    print(f\"   Expected structure: {DRIVE_ROOT}/vivos/vivos/train/waves/...\")\n",
    "\n",
    "# Verify\n",
    "if COLAB_VIVOS.exists():\n",
    "    # Count audio files\n",
    "    wav_files = list(COLAB_VIVOS.rglob(\"*.wav\"))\n",
    "    print(f\"\\n‚úÖ Audio files ready: {len(wav_files):,} WAV files\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Audio files not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3472dbb8",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287096f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Configuration - T·ªëi ∆∞u cho Colab GPU\n",
    "config = {\n",
    "    'pretrained_model': 'nguyenvulebinh/wav2vec2-base-vietnamese-250h',\n",
    "    'num_train_epochs': 30,          # S·ªë epochs\n",
    "    'batch_size': 16,                # GPU T4 ~ 16GB RAM\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'learning_rate': 3e-4,\n",
    "    'use_fp16': True,                # Mixed precision training\n",
    "    'apply_quantization': False,     # Kh√¥ng quantize khi training\n",
    "    'save_steps': 500,               # L∆∞u checkpoint m·ªói 500 steps\n",
    "    'eval_steps': 500,               # Evaluate m·ªói 500 steps\n",
    "}\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR = Path(f\"{DRIVE_ROOT}/models/wav2vec2-vietnamese\")\n",
    "FINAL_MODEL_DIR = Path(f\"{DRIVE_ROOT}/final_model\")\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FINAL_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save config\n",
    "with open(OUTPUT_DIR / 'config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   - {key}: {value}\")\n",
    "print(f\"\\nüìÅ Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996da0e5",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Load Processor & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "from src.data.preprocessing import load_and_prepare_datasets\n",
    "\n",
    "print(\"Loading processor...\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(config['pretrained_model'])\n",
    "\n",
    "print(\"\\nLoading datasets...\")\n",
    "print(\"‚ö†Ô∏è This may take 5-10 minutes...\")\n",
    "\n",
    "# Change to Vietnamese-asr directory to use relative paths\n",
    "os.chdir('/content/Vietnamese-asr')\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = load_and_prepare_datasets(\n",
    "    str(DATA_DIR / 'train.jsonl'),\n",
    "    str(DATA_DIR / 'validation.jsonl'),\n",
    "    str(DATA_DIR / 'test.jsonl'),\n",
    "    processor\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets loaded:\")\n",
    "print(f\"   - Train: {len(train_dataset):,} samples\")\n",
    "print(f\"   - Validation: {len(val_dataset):,} samples\")\n",
    "print(f\"   - Test: {len(test_dataset):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5678ff9",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.train_wav2vec2 import create_model\n",
    "\n",
    "print(\"Creating model...\")\n",
    "vocab_size = len(processor.tokenizer)\n",
    "model = create_model(vocab_size, config['pretrained_model'])\n",
    "\n",
    "# Move to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úÖ Model ready on {device}\")\n",
    "print(f\"   - Total parameters: {total_params:,}\")\n",
    "print(f\"   - Trainable: {trainable_params:,}\")\n",
    "print(f\"   - Frozen: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10264c",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Start Training\n",
    "\n",
    "**‚è±Ô∏è Estimated time: 15-20 hours on T4 GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1711c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.train_wav2vec2 import train_model\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ Starting Training...\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANT:\")\n",
    "print(\"   - Keep this tab open!\")\n",
    "print(\"   - Colab timeout: ~12 hours\")\n",
    "print(\"   - Checkpoints auto-saved to Drive every 500 steps\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Train\n",
    "trainer = train_model(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    processor=processor,\n",
    "    output_dir=str(OUTPUT_DIR),\n",
    "    num_train_epochs=config['num_train_epochs'],\n",
    "    batch_size=config['batch_size'],\n",
    "    gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "    learning_rate=config['learning_rate'],\n",
    "    use_fp16=config['use_fp16']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b71d0bb",
   "metadata": {},
   "source": [
    "## üîü Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c156254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving final model...\")\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(str(FINAL_MODEL_DIR))\n",
    "processor.save_pretrained(str(FINAL_MODEL_DIR))\n",
    "\n",
    "# Save training history\n",
    "import pandas as pd\n",
    "if hasattr(trainer.state, 'log_history'):\n",
    "    history_df = pd.DataFrame(trainer.state.log_history)\n",
    "    history_df.to_csv(f\"{DRIVE_ROOT}/training_history.csv\", index=False)\n",
    "    print(f\"‚úì Training history saved\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"üì¶ Final model: {FINAL_MODEL_DIR}\")\n",
    "print(f\"\\nüí° Model ƒë√£ l∆∞u v√†o Google Drive, b·∫°n c√≥ th·ªÉ:\")\n",
    "print(f\"   1. Download v·ªÅ m√°y t·ª´ Drive\")\n",
    "print(f\"   2. D√πng tr·ª±c ti·∫øp t·ª´ Drive trong notebook kh√°c\")\n",
    "print(f\"   3. Upload l√™n HuggingFace Hub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cdf5d4",
   "metadata": {},
   "source": [
    "## üìä Monitor Training (Optional)\n",
    "\n",
    "Ch·∫°y cell n√†y trong l√∫c training ƒë·ªÉ theo d√µi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {OUTPUT_DIR}/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU monitoring\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check latest checkpoint\n",
    "!ls -lh {OUTPUT_DIR}/checkpoint-*/ | tail -5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c183b1",
   "metadata": {},
   "source": [
    "## üéØ Test Model (After Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import soundfile as sf\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(str(FINAL_MODEL_DIR))\n",
    "processor = Wav2Vec2Processor.from_pretrained(str(FINAL_MODEL_DIR))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio file\n",
    "def transcribe(audio_path):\n",
    "    # Load audio\n",
    "    speech, sr = sf.read(audio_path)\n",
    "    \n",
    "    # Process\n",
    "    inputs = processor(speech, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    # Decode\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(pred_ids)[0]\n",
    "    \n",
    "    return transcription\n",
    "\n",
    "# Test\n",
    "# audio_file = \"/path/to/audio.wav\"\n",
    "# result = transcribe(audio_file)\n",
    "# print(f\"Transcription: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa6409",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Tips\n",
    "\n",
    "### Tr√°nh Colab timeout:\n",
    "- Training m·∫•t ~15-20h, Colab free timeout sau ~12h\n",
    "- **Gi·∫£i ph√°p:** Chia nh·ªè training th√†nh nhi·ªÅu session\n",
    "  ```python\n",
    "  # Session 1: Train 10 epochs\n",
    "  config['num_train_epochs'] = 10\n",
    "  \n",
    "  # Session 2: Resume t·ª´ checkpoint, train th√™m 10 epochs\n",
    "  config['resume_from_checkpoint'] = str(OUTPUT_DIR / 'checkpoint-5000')\n",
    "  config['num_train_epochs'] = 20\n",
    "  ```\n",
    "\n",
    "### Colab Pro:\n",
    "- Timeout: ~24h\n",
    "- Better GPU: A100/V100\n",
    "- Training time: ~8-10h\n",
    "\n",
    "### Auto-save to Drive:\n",
    "Checkpoints t·ª± ƒë·ªông l∆∞u v√†o Drive m·ªói 500 steps, an to√†n n·∫øu Colab disconnect!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
